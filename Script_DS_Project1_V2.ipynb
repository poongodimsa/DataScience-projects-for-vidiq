{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Script_DS_Project1_V2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rWivJFDq4zsa",
        "NlXDBvN74zP1",
        "25_-Npp436K2",
        "esTpLsjFNRUe",
        "mbNc1DpLNYiS",
        "4y-Qiu-53WdG"
      ],
      "authorship_tag": "ABX9TyOG9W8rMBJwoeP+k4X5V3t0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poongodimsa/DataScience-projects-for-vidiq/blob/main/Script_DS_Project1_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 1 -  Revenue by customer by month - V 1"
      ],
      "metadata": {
        "id": "NwKkzYgAyZBF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Version 2 - Specs\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rWivJFDq4zsa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's call all files \"Platform YY.MM.DD\", so if we ran the Stripe output today, it would be called \"Stripe 22.06.17\", to be applied to PayPal and ChartMogul as well. Can you also add a folder in the \"Results\" folder called Archives, and put all old output files in there?\n",
        "--> Will rename accordingly. I will code the script to move all the files under 'Results' to 'Archive' before creating a new file for the run. \n",
        "\n",
        "** Stripe Output: **\n",
        "\n",
        "\n",
        "In the output file:Country: In the Stripe raw data files, column AK \"card_country\" provides a 2 digit country code. Pls use this.Plan Name: In the Stripe raw data files, col AL \"statement_descriptor\" provides the Plan. Pls use this for Customer Plan in the output.Plan Duration - Appears unavailable here\n",
        "Customer Name - Appears unavailable hereLet's add an index column for Customer Email. This might work in lieu of a Name. Note we'll want to do this in PayPal too, so all Indexes match. That might mean Customer Unique ID will be something else for PayPal.\n",
        "\n",
        "\n",
        "PayPal Output:\n",
        "\n",
        "Country: \n",
        "There is a 2 digit country code like Stripe, we should try to have data conventions match if possible, so pls use this where we can. If this is N/A, your current output pulls from the PayPal raw data col \"Country\". However, there are many N/As. Finally, country is also provided in the last part of the \"Shipping Address\". Pls have your script try to pull from these three in this order, so if the 2 digit code is avail, pull that. If not, pull from \"country\". If that's not available, from col N \"Shipping Address\" by slicing the string off up to the last comma.  Between the 3 of these, we should be able to get nearly all countries. Plan: Can be found in Subject. It should either be Pro, Boost or Max. Your current output has some inaccurate info for plans - for example, we don't have a \"Gold Plan\", so not sure that that is. Duration: This can also be found in Subject, there is says \"monthly\" or \"yearly\". Just do a string search and if either of these are found in the row, add them to the duration.\n"
      ],
      "metadata": {
        "id": "-QwfzTuC6f35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Version 1 - Specifications - For Paypal only"
      ],
      "metadata": {
        "id": "NlXDBvN74zP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Final result:\n",
        "\n",
        "1. Get EUR customer email addresses to USD amounts from EUR amounts\n",
        "\n",
        "2. Remove /ignore all EUR amounts from the calculation. If you add all EUR (net) together. This will give you zero value\n",
        "\n",
        "3. Ignore any amounts under \"payments@vid.io\" - Anway there will be no amounts for this email if you do the above two steps\n",
        "\n",
        "\n",
        "#### Description:\n",
        "\n",
        "Some of our customers pay in EUR. Since our default currency is USD, Paypal immediately converts these EUR payments to USD\n",
        "\n",
        "The Problem we have; See the below screenshot taken from the 2022.02 Payroll data file. (A:5 to A:7)\n",
        "\n",
        "Patrick is a EU customer. he paid us in EU currency. EUR 10.00\n",
        "Paypal immediately converted to USD 9.84\n",
        "You can also see that when you add both EUR amounts it will net set off ( Zero value)\n",
        "So in these multi-currency cases, we need to get the USD values only. But the problem; there is no email address as the unique ID assigned to USD amounts. It is blank\n",
        "\n",
        "The workaround here is \n",
        "In the above case, the Customer's email is knopey@gmx.de. But this is assigned to the EUR amount instead of the USD amount.\n",
        "\n",
        "Transaction ID - 5RE84019JL6683131 This is the reference for the EUR amount. But we have a different reference for the USD amount. So we cannot use that get the customer email\n",
        "\n",
        "Reference Txn ID - 5RE84019JL6683131 - Check the reference under \"Reference Txn ID\" for the USD amount now compare this with the above transaction ID. You will see there is a match\n",
        "In Excel, we can use the \"VlookUp\" formula to get the customer email to USD amount using these two different IDs\n",
        "Now please find a way to get the correct email ID to USD amount\n",
        "\n",
        "**Important: Consider 'To Mail address' as unique id for debit transactions.**"
      ],
      "metadata": {
        "id": "jvEgfhlL5I9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Dg29bsE8KuXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Version 0 - Specifications\n",
        "---"
      ],
      "metadata": {
        "id": "25_-Npp436K2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Headers - Months in format “YYYY-MM”\n",
        "\n",
        "Row Indexes - \n",
        "1.\tCustomer Name\n",
        "2.\tPlatform (Stripe or PayPal)\n",
        "3.\tCustomer Unique ID\n",
        "4.\tCustomer Country (if available)\n",
        "5.\tCustomer Plan (Pro or Boost; if available)\n",
        "6.\tCustomer Plan Duration (Monthly or Yearly, if available)\n",
        "\n",
        "Rows - Unique customers\n",
        "\n",
        "Values - sum of total payments (received and refunded) per month for each customer\n",
        "\n",
        "1.\tStripe - \n",
        "\n",
        "○\tuse \"customer_id\" as the unique ID to get the data\n",
        "2.\tPayPal\n",
        "\n",
        "○\tImportant -----> Consider Only \"Subscription Payment\" & \"Payment Refund\" types (\"E\" column in the PayPal statements). Remove all the other types\n",
        "\n",
        "○\tUse \"From Email Address\" as the unique ID to get the data ( There is no special code for customer) \n",
        "\n",
        "3.\tIgnore ChartMogul (“CM”) for now. This will be used in the second iteration.\n",
        "\n",
        "Output\n",
        "\n",
        "●\tshould be an excel file with one tab of revenue per customer per month\n",
        "\n",
        "●\tSort by start month\n",
        "\n",
        "\n",
        "Stripe\n",
        "\n",
        "Customer Plan - You can map to \"statement_descriptor\" ( AL Column)\n",
        "\n",
        "Customer Plan Duration - N/A - You Can keep this blank\n",
        "\n",
        "Sum of total payments per customer ------> Always use Gross Amounts (G Column)\n",
        "\n",
        "Paypal\n",
        "\n",
        "Customer Unique ID - map to 'From Email Address? - \"YES\"\n",
        "\n",
        "Customer Plan - You Can map the \"Subject\" /  \"AD\" Column \n",
        "\n",
        "Customer Plan Duration - N/A - You Can keep this blank\n",
        "\n",
        "Amounts -----> Always use Gross Amounts / \"H\" Column\n",
        "\n"
      ],
      "metadata": {
        "id": "JuFhgd5K1TpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Script\n",
        "---"
      ],
      "metadata": {
        "id": "FHvKpNaw3tjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports,prepartions and functions"
      ],
      "metadata": {
        "id": "0RPucTYS4SMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime\n",
        "from datetime import date\n",
        "from dateutil.relativedelta import *\n",
        "import shutil\n"
      ],
      "metadata": {
        "id": "SanXBAdhNeuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Preparations\n",
        "---\n"
      ],
      "metadata": {
        "id": "vL4YBOciZNdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#Set file paths\n",
        "path = \"/content/gdrive/My Drive/Data Science 2022/\"\n",
        "\n",
        "inpathST = path + \"Stripe/\"\n",
        "inpathPP = path + \"PayPal/\"\n",
        "inpathCM = path + \"CM/\"\n",
        "\n",
        "outpath = path + \"Results/\"\n",
        "archpath = path + \"Results/Archives/\"\n",
        "\n",
        "#Create Results folder if missing\n",
        "if not os.path.isdir(outpath):\n",
        "  os.mkdir(outpath)\n",
        "\n",
        "#Create archive folder if missing\n",
        "if not os.path.isdir(archpath):\n",
        "  os.mkdir(archpath)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaAgaFqFStup",
        "outputId": "22738c89-5b3a-4733-b79f-c4fda28d114d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Move files if any in 'Results' to 'Archives'\n",
        "for rfile in os.listdir(outpath):\n",
        "  if os.path.isfile(outpath+rfile):\n",
        "    src = outpath + rfile\n",
        "    dest = archpath + rfile\n",
        "    shutil.move(src, dest)"
      ],
      "metadata": {
        "id": "AgUYi4Kzn4x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Functions common to all\n",
        "\n",
        "------\n"
      ],
      "metadata": {
        "id": "TmiQGeR5P55u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_month_headers(startmonth,monthcount):\n",
        "  '''\n",
        "  Function: Returns list of dates starting from 'startmonth' incrementing till 'monthcount' counts\n",
        "  startdate: date in format 'YYYY-MM' as string datatype\n",
        "  monthcount: Number of increments\n",
        "  '''\n",
        "  lstout = [] #Intialize\n",
        "  start = datetime.strptime(startmonth,'%Y-%m') \n",
        "  for c in range(monthcount):\n",
        "    lstout.append((start + relativedelta(months=+c)).strftime('%Y-%m'))\n",
        "  return(lstout)\n",
        "\n",
        "def gen_header():\n",
        "  ''' Gnerates common header '''\n",
        "\n",
        "  lstheader = [ \"Customer Name\",\"Platform\",\"Customer Unique ID\", \"Customer Country\", \"Customer Plan\", \"Customer Plan Duration\" ]\n",
        "  lstmonths = get_month_headers('2020-01', 27)\n",
        "  return(lstheader + lstmonths)\n",
        "\n",
        "def getdate():\n",
        "  ''' return todays date in yy.mm.dd format '''\n",
        "  \n",
        "  today = date.today()\n",
        "  return today.strftime(\"%y.%m.%d\")\n"
      ],
      "metadata": {
        "id": "7-Qv9DxGfSsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loop through the input files to calculate revenue per customer"
      ],
      "metadata": {
        "id": "MNY4J0FsZWx_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stripe"
      ],
      "metadata": {
        "id": "esTpLsjFNRUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c=0\n",
        "for file in sorted(os.listdir(inpathST)):\n",
        "  c+=1\n",
        "  print(file)\n",
        "  df = pd.read_csv(inpathST + file, na_filter=False, index_col=False)\n",
        "\n",
        "  #Change the data type of gross to numeric\n",
        "  df = df.astype({\"gross\": str})\n",
        "  df['gross'] = df['gross'].str.replace(',','')\n",
        "  df = df.astype({\"gross\": float})\n",
        "\n",
        "\n",
        "  #*********** Calculate revenue per customer per month ******************\n",
        "  #Apply Group by to input data\n",
        "  sum_df = df.groupby(['customer_id' ], as_index=False).agg({'customer_name':'first', 'customer_id':'first',\n",
        "                                                            'card_country':'first', 'statement_descriptor':'first','gross': 'sum'}) #grouped by dataframe'\n",
        "  sum_df = sum_df.sort_values('customer_id')\n",
        "  \n",
        "  #Form revenue headers\n",
        "  month = '20' + file[7:12].replace('.','-') #From input file name\n",
        "  sum_df.rename(columns={'customer_name':'Customer Name', 'customer_id':'Customer Unique ID', \n",
        "                        'card_country': \"Customer Country\",'statement_descriptor':'Customer Plan', 'gross': month},inplace = True)\n",
        "  \n",
        "  \n",
        "  \n",
        "  #Create base dataframe from first file\n",
        "  if c==1:\n",
        "    final_df=sum_df.copy()\n",
        "  else:\n",
        " \n",
        "    #Merge using full outer join\n",
        "    final_df = final_df.merge(sum_df, how='outer', on = 'Customer Unique ID')\n",
        "\n",
        "    #************* V2 change: Keep the latest info for customer name, country and plan. If latest is null then copy from the previous record ***************\n",
        "    #1. If gross is null for current month records means no data found in current file for that particular customer. Just ignore _y values. Copy _x to _y since we will drop _x records\n",
        "    #2. If gross is not null but _y values are null, just copy _x values to _y\n",
        "    #3. If gross is null in final_df then the customer is new. Do nothing. _x cols willbe deleted\n",
        "\n",
        "    #Convert dataframe to dictionary and iterate which is faster than iterrows and itertuples\n",
        "    final_dict = final_df.to_dict('records')\n",
        "\n",
        "    # Check if _y values are null. If so copy _x value to _y. This way we get latest not null values\n",
        "    for row in final_dict:\n",
        "      if (row['Customer Name_y'] != row['Customer Name_y']) or (not  row['Customer Name_y']): #Checking for null in strings compare to itself returns false if nan\n",
        "        row['Customer Name_y'] = row['Customer Name_x']\n",
        "      if (row['Customer Country_y'] != row['Customer Country_y']) or (not row['Customer Country_y']):\n",
        "        row['Customer Country_y'] = row['Customer Country_x']\n",
        "      if (row['Customer Plan_y'] != row['Customer Plan_y']) or (not  row['Customer Plan_y']) : #Checking for null in strings\n",
        "        row['Customer Plan_y'] = row['Customer Plan_x'] \n",
        "\n",
        "    #Convert dictinary back to dataframe\n",
        "    final_df = pd.DataFrame.from_dict(final_dict)\n",
        "\n",
        "    #Drop columns with '_x\n",
        "    cols = [col for col in final_df.columns if col.lower()[-2:] != '_x']\n",
        "    final_df=final_df[cols]\n",
        "\n",
        "    #Remove '_y' from column name\n",
        "    for col in final_df.columns:\n",
        "      if col.lower()[-2:] == '_y':\n",
        "        final_df.rename(columns = {col: col[:-2]}, inplace=True)\n",
        "\n",
        "    \n",
        "#insert 'Platform' and 'customer plan duration' cols\n",
        "final_df.insert(1,\"Platform\", \"Stripe\")\n",
        "final_df.insert(1,'Customer Plan Duration',\"\")\n",
        "\n",
        "\n",
        "#Reorder the headers\n",
        "lsthead = gen_header()\n",
        "final_df = final_df.reindex(columns=lsthead)\n",
        "\n",
        "#Sort by first month\n",
        "final_df = final_df.sort_values('2020-01')\n",
        "\n",
        "#Let's call all files \"Platform YY.MM.DD\"\n",
        "dt = getdate()\n",
        "outfilename = \"Stripe \" + dt + '.csv'\n",
        "\n",
        "#Export data to excel without index\n",
        "final_df.to_csv(outpath + outfilename, index = False)\n",
        "\n",
        "print('done')"
      ],
      "metadata": {
        "id": "g1lSZmt2AGeN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b85ab0e6-c7f8-443c-f82c-de52f41c0aed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stripe_20.01.csv\n",
            "stripe_20.02.csv\n",
            "stripe_20.03.csv\n",
            "stripe_20.04.csv\n",
            "stripe_20.05.csv\n",
            "stripe_20.06.csv\n",
            "stripe_20.07.csv\n",
            "stripe_20.08.csv\n",
            "stripe_20.09.csv\n",
            "stripe_20.10.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stripe_20.11.csv\n",
            "stripe_20.12.csv\n",
            "stripe_21.01.csv\n",
            "stripe_21.02.csv\n",
            "stripe_21.03.csv\n",
            "stripe_21.04.csv\n",
            "stripe_21.05.csv\n",
            "stripe_21.06.csv\n",
            "stripe_21.07.csv\n",
            "stripe_21.08.csv\n",
            "stripe_21.09.csv\n",
            "stripe_21.10.csv\n",
            "stripe_21.11.csv\n",
            "stripe_21.12.csv\n",
            "stripe_22.01.csv\n",
            "stripe_22.02.csv\n",
            "stripe_22.03.csv\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PayPal"
      ],
      "metadata": {
        "id": "mbNc1DpLNYiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "c=0\n",
        "for file in sorted(os.listdir(inpathPP)):\n",
        "  c+=1\n",
        "  print(file)\n",
        "  #Read file to dataframe\n",
        "  df = pd.read_csv(inpathPP + file, encoding = \"ISO-8859-1\", na_filter=False, index_col=False)\n",
        "\n",
        "  #Consider Only \"Subscription Payment\" & \"Payment Refund\" types (\"E\" column in the PayPal statements). Remove all the other types\n",
        "  #Include \"General Currency Conversion\" in the Filter to get USD for other currencies\n",
        "  df = df[(df[\"Type\"] == \"Subscription Payment\") | (df[\"Type\"] == \"Payment Refund\") | (df[\"Type\"] == \"General Currency Conversion\")].copy()\n",
        "\n",
        "  df = df[[\"From Email Address\",\"To Email Address\",\"Name\",\"Country Code\", \"Country\",\"Shipping Address\",\"Subject\", \"Gross\",\"Balance Impact\",\n",
        "          \"Currency\",\"Type\",\"Transaction ID\",\"Reference Txn ID\"]].copy()\n",
        "\n",
        "  #Unique Id - If 'Balance Impact\" is 'Credit' use 'From email address' else use 'To Email Address'\n",
        "  #Convert dataframe to dictionary for iterating efficiency\n",
        "  nonedata = [None] * len(df)\n",
        "  dftemp = df.assign(Email = nonedata)\n",
        "  \n",
        "  tempdict = dftemp.to_dict('records')\n",
        "  \n",
        "  for row in tempdict:\n",
        "    if row['Balance Impact'] == \"Credit\":\n",
        "      #dftemp.loc[len(dftemp.index)] = [row[\"From Email Address\"]]\n",
        "      row['Email'] = row[\"From Email Address\"]\n",
        "    elif row['Balance Impact'] == \"Debit\":\n",
        "      row['Email'] = row[\"To Email Address\"]\n",
        "\n",
        "    #V2- Keep country code, if it is empty, keep country, if empty strip from shipping address\n",
        "    if (row['Country Code'] != row['Country Code']) or (not row['Country Code']):\n",
        "      if (row['Country'] != row['Country']) or (not row['Country']):\n",
        "        if (row['Shipping Address'] != row['Shipping Address']) or (not row['Shipping Address']):\n",
        "          row['Country'] = ''\n",
        "        else:\n",
        "          #Get country from last part of shipping address\n",
        "          row['Country'] = (row[\"Shipping Address\"].split(',')[-1]).strip()\n",
        "      else:\n",
        "        row['Country'] = row['Country']\n",
        "    else:\n",
        "      row['Country'] = row['Country Code']\n",
        "\n",
        "  \n",
        "  df = pd.DataFrame.from_dict(tempdict)\n",
        "  #Reset index to avoid null values\n",
        "  df.reset_index(drop=True, inplace = True)\n",
        "\n",
        "  #************************************* Logic to get email from other currency record to USD ******************\n",
        "  #DF to copy email from \n",
        "  dffrom = df[ (df['Currency'] != \"USD\") & (( df['Type'] == \"Subscription Payment\") | (df[\"Type\"] == \"Payment Refund\")) ].copy()\n",
        "  # df copy to\n",
        "  dfto = df[ (df['Currency'] == \"USD\") & ( df['Type'] == \"General Currency Conversion\")].copy()\n",
        "\n",
        "  if not dfto.empty:\n",
        "    dictfrom = dffrom.to_dict('records')\n",
        "    dictto = dfto.to_dict('records')\n",
        "    \n",
        "    for rowf in dictfrom:\n",
        "      txnid = rowf['Transaction ID']\n",
        "      for rowt in dictto:\n",
        "        if (rowt['Reference Txn ID'] == txnid):\n",
        "          rowt['Email'] = rowf['Email']\n",
        "          rowt['Name'] = rowf['Name']\n",
        "          rowt['Country'] = rowf['Country']\n",
        "          rowt['Subject'] = rowf['Subject']\n",
        "\n",
        "    dfto = pd.DataFrame.from_dict(dictto)\n",
        "    \n",
        "    #Delete all empty 'Email' entries from dfto as it does not comply with 'Type' -'subs pay' or 'pay refund'\n",
        "    dfto = dfto [(pd.isnull(dfto['Email']) == False)].copy()\n",
        "    #Reset index to avoid null values\n",
        "    dfto.reset_index(drop=True, inplace = True)\n",
        "  \n",
        "  df.reset_index(drop=True, inplace = True)\n",
        "\n",
        "  dfnew = pd.concat([df,dfto], axis = 0)\n",
        "  dfnew.reset_index(drop=True, inplace = True)\n",
        "\n",
        "  \n",
        "  #Now we have email ids for USD records\n",
        "  #Delete all currencies other than 'USD' and all entries with blank 'Email'\n",
        "  df = dfnew[(dfnew['Currency'] == \"USD\") & (pd.isnull(dfnew['Email']) == False)].copy()\n",
        "  \n",
        "  df = df[[\"Email\",\"Name\",\"Country\",\"Subject\", \"Gross\"]].copy()\n",
        "\n",
        "  \n",
        "  #Change the data type of gross to numeric\n",
        "  df = df.astype({\"Gross\": str})\n",
        "  df['Gross'] = df['Gross'].str.replace(',','')\n",
        "  df = df.astype({\"Gross\": float})\n",
        "\n",
        "  #************************* Calculate revenue per customer per month ******************\n",
        "  #Apply Group by to input data\n",
        "  sum_df = df.groupby(['Email' ], as_index=False).agg({'Name':'first', 'Email':'first',\n",
        "                                                            'Country':'first', 'Subject':'first', 'Gross': 'sum'})     #grouped by dataframe'\n",
        "  sum_df = sum_df.sort_values('Email')\n",
        "  \n",
        "  #Form revenue headers\n",
        "  month =  file[7:14].replace('.','-')  #From input file name\n",
        "\n",
        "  sum_df.rename(columns={'Name':'Customer Name', 'Email':'Customer Unique ID', \n",
        "                        'Country': \"Customer Country\",'Subject':'Customer Plan','Gross': month},inplace = True)\n",
        "  \n",
        "  \n",
        "  #Create base dataframe from first file\n",
        "  if c==1:\n",
        "    final_df=sum_df.copy()\n",
        "    \n",
        "  else:\n",
        "    \n",
        "    #Merge using full outer join\n",
        "    final_df = final_df.merge(sum_df, how='outer', on = 'Customer Unique ID')\n",
        "\n",
        "    #************* V2 change: Keep the latest info for customer name, country and plan. If latest is null then copy from the previous record ***************\n",
        "    #1. If gross is null for current month records means no data found in current file for that particular customer. Just ignore _y values. Copy _x to _y since we will drop _x records\n",
        "    #2. If gross is not null but _y values are null, just copy _x values to _y\n",
        "    #3. If gross is null in final_df then the customer is new. Do nothing. _x cols willbe deleted\n",
        "\n",
        "    #Convert dataframe to dictionary and iterate which is faster than iterrows and itertuples\n",
        "    final_dict = final_df.to_dict('records')\n",
        "\n",
        "    # Check if _y values are null. If so copy _x value to _y. This way we get latest not null values\n",
        "    for row in final_dict:\n",
        "      if (row['Customer Name_y'] != row['Customer Name_y']) or (not  row['Customer Name_y']): #Checking for null in strings compare to itself returns false if nan\n",
        "        row['Customer Name_y'] = row['Customer Name_x']\n",
        "      if (row['Customer Country_y'] != row['Customer Country_y']) or (not row['Customer Country_y']):\n",
        "        row['Customer Country_y'] = row['Customer Country_x']\n",
        "      if (row['Customer Plan_y'] != row['Customer Plan_y']) or (not  row['Customer Plan_y']) : #Checking for null in strings\n",
        "        row['Customer Plan_y'] = row['Customer Plan_x'] \n",
        "      \n",
        "      \n",
        "    #Convert dictinary back to dataframe\n",
        "    final_df = pd.DataFrame.from_dict(final_dict)\n",
        "\n",
        "    #Drop columns with '_x\n",
        "    cols = [col for col in final_df.columns if col.lower()[-2:] != '_x']\n",
        "    final_df=final_df[cols]\n",
        "\n",
        "    #Remove '_y' from column name\n",
        "    for col in final_df.columns:\n",
        "      if col.lower()[-2:] == '_y':\n",
        "        final_df.rename(columns = {col: col[:-2]}, inplace=True)\n",
        "\n",
        "#insert 'Platform' and 'customer plan duration' cols\n",
        "final_df.insert(1,\"Platform\", \"PayPal\")\n",
        "final_df.insert(1,'Customer Plan Duration',\"\")\n",
        "\n",
        "final_dict1 = final_df.to_dict('records')\n",
        "\n",
        "# Check if _y values are null. If so copy _x value to _y. This way we get latest not null values\n",
        "for row in final_dict1:\n",
        "  #V2 - Extract plan duration from customer plan\n",
        "  plan = str(row['Customer Plan'])\n",
        "  if ((plan.lower().find('monthly')) != -1) or ((plan.lower().find('month')) != -1):\n",
        "    row['Customer Plan Duration'] = 'Monthly'\n",
        "  elif (plan.lower().find('yearly')) != -1:\n",
        "    row['Customer Plan Duration'] = 'Yearly'\n",
        "\n",
        "#Convert dictinary back to dataframe\n",
        "final_df = pd.DataFrame.from_dict(final_dict1)\n",
        "\n",
        "#Reorder the headers\n",
        "lsthead = gen_header()\n",
        "final_df = final_df.reindex(columns=lsthead)\n",
        "\n",
        "#Sort by first month\n",
        "final_df = final_df.sort_values('2020-01')\n",
        "\n",
        "dt = getdate()\n",
        "outfilename = \"PayPal \" + dt + '.csv'\n",
        "\n",
        "#Export data to excel without index\n",
        "final_df.to_csv(outpath + outfilename,index = False)\n",
        "\n",
        "print('done')  "
      ],
      "metadata": {
        "id": "CTOUoEhlkyVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4d22762-0c74-425d-d4ef-ba2c8506bd68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paypal_2020.01.csv\n",
            "Paypal_2020.02.csv\n",
            "Paypal_2020.03.csv\n",
            "Paypal_2020.04.csv\n",
            "Paypal_2020.05.csv\n",
            "Paypal_2020.06.csv\n",
            "Paypal_2020.07.csv\n",
            "Paypal_2020.08.csv\n",
            "Paypal_2020.09.csv\n",
            "Paypal_2020.10.csv\n",
            "Paypal_2020.11.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paypal_2020.12.csv\n",
            "Paypal_2021.01.csv\n",
            "Paypal_2021.02.csv\n",
            "Paypal_2021.03.csv\n",
            "Paypal_2021.04.CSV\n",
            "Paypal_2021.05.CSV\n",
            "Paypal_2021.06.csv\n",
            "Paypal_2021.07.csv\n",
            "Paypal_2021.08.csv\n",
            "Paypal_2021.09.CSV\n",
            "Paypal_2021.10.csv\n",
            "Paypal_2021.11.csv\n",
            "Paypal_2021.12.csv\n",
            "Paypal_2022.01.csv\n",
            "Paypal_2022.02.csv\n",
            "Paypal_2022.03.csv\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ChartMogul"
      ],
      "metadata": {
        "id": "4y-Qiu-53WdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c=0\n",
        "for file in sorted(os.listdir(inpathCM)):\n",
        "  c+=1\n",
        "  print(file)\n",
        "  df = pd.read_csv(inpathCM + file, na_filter=False, index_col=False)\n",
        "\n",
        "  #Change the data type to numeric\n",
        "  df = df.astype({\"Line Item Value Account Currency\": str})\n",
        "  df['Line Item Value Account Currency'] = df[\"Line Item Value Account Currency\"].str.replace(',','')\n",
        "  df = df.astype({\"Line Item Value Account Currency\": float})\n",
        "  \n",
        "\n",
        "  #*********** Calculate revenue per customer per month ******************\n",
        "  #Apply Group by to input data\n",
        "  sum_df = df.groupby(['Customer External ID' ], as_index=False).agg({'Customer Name':'first', 'Customer External ID':'first',\n",
        "                                                             'Line Item Name':'first','Line Item Value Account Currency': 'sum'}) #grouped by dataframe'\n",
        "  sum_df = sum_df.sort_values('Customer External ID')\n",
        "  \n",
        "  #Form revenue headers\n",
        "  month = '20' + file[3:8].replace('.','-') #From input file name\n",
        "  sum_df.rename(columns={'Customer External ID':'Customer Unique ID', \n",
        "                        'Line Item Name':'Customer Plan', 'Line Item Value Account Currency': month},inplace = True)\n",
        "  \n",
        "  #Create base dataframe from first file\n",
        "  if c==1:\n",
        "    final_df=sum_df.copy()\n",
        "  else:\n",
        " \n",
        "    #Merge using full outer join\n",
        "    final_df = final_df.merge(sum_df, how='outer', on = 'Customer Unique ID')\n",
        "\n",
        "    #************* V2 change: Keep the latest info for customer name, country and plan. If latest is null then copy from the previous record ***************\n",
        "    #1. If gross is null for current month records means no data found in current file for that particular customer. Just ignore _y values. Copy _x to _y since we will drop _x records\n",
        "    #2. If gross is not null but _y values are null, just copy _x values to _y\n",
        "    #3. If gross is null in final_df then the customer is new. Do nothing. _x cols willbe deleted\n",
        "\n",
        "    #Convert dataframe to dictionary and iterate which is faster than iterrows and itertuples\n",
        "    final_dict = final_df.to_dict('records')\n",
        "\n",
        "    # Check if _y values are null. If so copy _x value to _y. This way we get latest not null values\n",
        "    for row in final_dict:\n",
        "      if (row['Customer Name_y'] != row['Customer Name_y']) or (not  row['Customer Name_y']): #Checking for null in strings compare to itself returns false if nan\n",
        "        row['Customer Name_y'] = row['Customer Name_x']\n",
        "      if (row['Customer Plan_y'] != row['Customer Plan_y']) or (not  row['Customer Plan_y']) : #Checking for null in strings\n",
        "        row['Customer Plan_y'] = row['Customer Plan_x'] \n",
        "\n",
        "    #Convert dictinary back to dataframe\n",
        "    final_df = pd.DataFrame.from_dict(final_dict)\n",
        "\n",
        "    #Drop columns with '_x\n",
        "    cols = [col for col in final_df.columns if col.lower()[-2:] != '_x']\n",
        "    final_df=final_df[cols]\n",
        "\n",
        "    #Remove '_y' from column name\n",
        "    for col in final_df.columns:\n",
        "      if col.lower()[-2:] == '_y':\n",
        "        final_df.rename(columns = {col: col[:-2]}, inplace=True)\n",
        "\n",
        "    \n",
        "#insert 'Platform' and 'customer plan duration' cols\n",
        "final_df.insert(1,\"Platform\", \"ChartMogul\")\n",
        "final_df.insert(1,'Customer Country',\"\")\n",
        "\n",
        "final_df.insert(1,'Customer Plan Duration',\"\")\n",
        "final_dict1 = final_df.to_dict('records')\n",
        "# Check if _y values are null. If so copy _x value to _y. This way we get latest not null values\n",
        "for row in final_dict1:\n",
        "  #V2 - Extract plan duration from customer plan\n",
        "  plan = str(row['Customer Plan'])\n",
        "  if ((plan.lower().find('monthly')) != -1) or ((plan.lower().find('month')) != -1):\n",
        "    row['Customer Plan Duration'] = 'Monthly'\n",
        "  elif ((plan.lower().find('yearly')) != -1) or ((plan.lower().find('year')) != -1):\n",
        "    row['Customer Plan Duration'] = 'Yearly'\n",
        "\n",
        "#Convert dictinary back to dataframe\n",
        "final_df = pd.DataFrame.from_dict(final_dict1)\n",
        "\n",
        "#Reorder the headers\n",
        "lsthead = gen_header()\n",
        "final_df = final_df.reindex(columns=lsthead)\n",
        "\n",
        "#Sort by first month\n",
        "final_df = final_df.sort_values('2020-01')\n",
        "\n",
        "#Let's call all files \"Platform YY.MM.DD\"\n",
        "dt = getdate()\n",
        "outfilename = \"CM \" + dt + '.csv'\n",
        "\n",
        "#To escape unicode error\n",
        "#final_df = final_df.applymap(lambda x: x.encode('unicode_escape').\n",
        " #                decode('utf-8') if isinstance(x, str) else x)\n",
        "\n",
        "#Export data to excel without index\n",
        "final_df.to_csv(outpath + outfilename, index = False)\n",
        "\n",
        "print('done')"
      ],
      "metadata": {
        "id": "dWQj-zfp3iQn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2b37e75-2d29-4af5-cfed-73f0b14922a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CM_20.01.csv\n",
            "CM_20.02.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CM_20.03.csv\n",
            "CM_20.04.csv\n",
            "CM_20.05.csv\n",
            "CM_20.06.csv\n",
            "CM_20.07.csv\n",
            "CM_20.08.csv\n",
            "CM_20.09.csv\n",
            "CM_20.10.csv\n",
            "CM_20.11.csv\n",
            "CM_20.12.csv\n",
            "CM_21.01.csv\n",
            "CM_21.02.csv\n",
            "CM_21.03.csv\n",
            "CM_21.04.csv\n",
            "CM_21.05.csv\n",
            "CM_21.06.csv\n",
            "CM_21.07.csv\n",
            "CM_21.08.csv\n",
            "CM_21.09.csv\n",
            "CM_21.10.csv\n",
            "CM_21.11.csv\n",
            "CM_21.12.csv\n",
            "CM_22.01.csv\n",
            "CM_22.02.csv\n",
            "CM_22.03.csv\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Verify Stripe with CM"
      ],
      "metadata": {
        "id": "RgHERnhyH3eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load current Stripe and CM aggregated fiels\n",
        "dt = getdate()\n",
        "\n",
        "#Load Stripe and chartmogul files\n",
        "infileS = \"Stripe \" + dt + '.csv'\n",
        "infileCM = \"CM \" + dt + '.csv'\n",
        "dfS = pd.read_csv(outpath + infileS)\n",
        "dfCM = pd.read_csv(outpath + infileCM)\n",
        "\n",
        "if not (dfS.empty and dfCM.empty):\n",
        "  #Inner join on 'cutomer unique id'\n",
        "  dfmerged = pd.merge(dfS,dfCM, on = \"Customer Unique ID\")\n",
        "  #Remove unnecessary columns\n",
        "  dfmerged.drop(['Platform_x', 'Customer Plan Duration_x','Platform_y','Customer Country_y'], axis = 1,inplace = True)\n",
        "  #Rename '_x' columns with 'Stripe' and _y columns with 'CM'\n",
        "  for col in dfmerged.columns:\n",
        "    if col.lower()[-2:] == '_x':\n",
        "      dfmerged.rename(columns = {col: (col[:-1] + 'Stripe')}, inplace=True)\n",
        "    elif col.lower()[-2:] == '_y':\n",
        "      dfmerged.rename(columns = {col: (col[:-1] + 'CM')}, inplace=True)\n",
        "  \n",
        "  #Reorder the headers so that stripe and CM data appear next to one another\n",
        "  lstcustomer = ['Customer Unique ID', 'Customer Name_Stripe', 'Customer Name_CM', 'Customer Country_Stripe',\n",
        "       'Customer Plan_Stripe', 'Customer Plan_CM','Customer Plan Duration_CM']\n",
        "  lstmonths = get_month_headers('2020-01', 27)\n",
        "  lstorderedmonths = []\n",
        "  for mon in lstmonths:\n",
        "    monS = str(mon) +'_Stripe'\n",
        "    monCM = str(mon) +'_CM'\n",
        "    lstorderedmonths.append(monS)\n",
        "    lstorderedmonths.append(monCM)\n",
        "  #List with headers in desired order\n",
        "  lstfinal  = lstcustomer + lstorderedmonths \n",
        "  \n",
        "  #THis dataframe has CM and Stripe info alternatively\n",
        "  dfmerged = dfmerged.reindex(columns=lstfinal)\n",
        "\n",
        "#*************** Find mismatches and write it seperately in a worksheet\n",
        "  merge_dict = dfmerged.to_dict('records')\n",
        " \n",
        "  dftemp = pd.DataFrame(columns = dfmerged.columns)\n",
        "  p=0\n",
        "  for row in merge_dict:\n",
        "    \n",
        "    for mon in lstmonths:\n",
        "      monS = str(mon) +'_Stripe'\n",
        "      monCM = str(mon) +'_CM'\n",
        "\n",
        "      if (row[monS] != row[monCM]):\n",
        "        if not((pd.isna(row[monS])) and (pd.isna(row[monCM]))) :\n",
        "          if  not( (row[monS] == 0.0) and pd.isna(row[monCM])):\n",
        "            if  not( (row[monCM] == 0.0) and pd.isna(row[monS])):\n",
        "              Sdata = \"%.2f\" % float(row[monS])\n",
        "              CMdata =\"%.2f\" % float(row[monCM])\n",
        "              if Sdata != CMdata:\n",
        "                df1 = {\"Customer Unique ID\":row[\"Customer Unique ID\"],'Customer Name_Stripe':row['Customer Name_Stripe'], 'Customer Name_CM':row['Customer Name_CM'],\n",
        "                      'Customer Country_Stripe':row['Customer Country_Stripe'],'Customer Plan_Stripe' : row['Customer Plan_Stripe'], 'Customer Plan_CM':row['Customer Plan_CM'],\n",
        "                      'Customer Plan Duration_CM':row['Customer Plan Duration_CM'],  monS:row[monS], monCM : row[monCM]}\n",
        "                dftemp = dftemp.append(df1, ignore_index = True)\n",
        "                \n",
        "    p += 1\n",
        "\n",
        "  #dftemp.to_excel(outpath + 'Stripe Vs CM Differences.xlsx', index=False)\n",
        "  #Sort by first month\n",
        "  dfmerged = dfmerged.sort_values('2020-01_CM')\n",
        "  dfmerged = dfmerged.applymap(lambda x: x.encode('unicode_escape').\n",
        "                 decode('utf-8') if isinstance(x, str) else x)\n",
        "\n",
        "  #dfmerged.to_csv(outpath + 'CM Vs Stripe.csv',index = False)\n",
        "  #dfmerged.to_excel(outpath + 'Stripe Vs CM.xlsx',index = False)\n",
        "\n",
        "  writer = pd.ExcelWriter(outpath + 'Stripe Vs CM.xlsx', engine = 'xlsxwriter')\n",
        "  dfmerged.to_excel(writer, sheet_name = 'Stripe Vs CM', ignore_index = True)\n",
        "  dftemp.to_excel(writer, sheet_name = 'Differences', ignore_index = True)\n",
        "  writer.save()\n",
        "  writer.close()\n",
        "\n",
        "  print('done')\n",
        "\n",
        "else:\n",
        "\n",
        "  print(\"No input files found!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEd6CuigH82D",
        "outputId": "83e0d46d-c992-4156-d973-40b4755f84b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/xlsxwriter/workbook.py:339: UserWarning: Calling close() on already closed file.\n",
            "  warn(\"Calling close() on already closed file.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "writer = pd.ExcelWriter(outpath + 'Stripe Vs CM.xlsx', engine = 'xlsxwriter')\n",
        "dfmerged.to_excel(writer, sheet_name = 'Stripe Vs CM', index = False)\n",
        "dftemp.to_excel(writer, sheet_name = 'Differences', index = False)\n",
        "writer.save()\n",
        "writer.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3Lhc36V1t_i",
        "outputId": "d7437e22-1f58-4743-d657-ff59c123ce82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/xlsxwriter/workbook.py:339: UserWarning: Calling close() on already closed file.\n",
            "  warn(\"Calling close() on already closed file.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1eevfRsn1uCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fV1iNsAbwEEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Verify Paypal with CM"
      ],
      "metadata": {
        "id": "WewJ7GQx3ITU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Paypal and CM revenues by month\n",
        "dt = getdate()\n",
        "\n",
        "infilePP = \"PayPal \" + dt + '.csv'\n",
        "infileCM = \"CM \" + dt + '.csv'\n",
        "dfPP = pd.read_csv(outpath + infilePP)\n",
        "dfCM = pd.read_csv(outpath + infileCM)\n",
        "\n",
        "if not (dfPP.empty and dfCM.empty):\n",
        "  #Inner join on 'cutomer unique id'\n",
        "  dfmerged = pd.merge(dfPP,dfCM, on = \"Customer Unique ID\")\n",
        "  #Remove unnecessary columns\n",
        "  dfmerged.drop(['Platform_x', 'Customer Plan Duration_x','Platform_y','Customer Country_y'], axis = 1,inplace = True)\n",
        "  #Rename '_x' columns with 'Stripe' and _y columns with 'CM'\n",
        "  for col in dfmerged.columns:\n",
        "    if col.lower()[-2:] == '_x':\n",
        "      dfmerged.rename(columns = {col: (col[:-1] + 'Stripe')}, inplace=True)\n",
        "    elif col.lower()[-2:] == '_y':\n",
        "      dfmerged.rename(columns = {col: (col[:-1] + 'CM')}, inplace=True)\n",
        "  \n",
        "  #Reorder the headers so that stripe and CM data appear next to one another\n",
        "  lstcustomer = ['Customer Unique ID', 'Customer Name_Stripe', 'Customer Name_CM', 'Customer Country_Stripe',\n",
        "       'Customer Plan_Stripe', 'Customer Plan_CM','Customer Plan Duration_CM']\n",
        "  lstmonths = get_month_headers('2020-01', 27)\n",
        "  lstorderedmonths = []\n",
        "  for mon in lstmonths:\n",
        "    monS = str(mon) +'_Stripe'\n",
        "    monCM = str(mon) +'_CM'\n",
        "    lstorderedmonths.append(monS)\n",
        "    lstorderedmonths.append(monCM)\n",
        "    \n",
        "  lstfinal  = lstcustomer + lstorderedmonths \n",
        "  \n",
        "  dfmerged = dfmerged.reindex(columns=lstfinal)\n",
        "\n",
        "\n",
        "  merge_dict = dfmerged.to_dict('records')\n",
        " \n",
        "  dftemp = pd.DataFrame(columns = dfmerged.columns)\n",
        "  p=0\n",
        "  for row in merge_dict:\n",
        "    \n",
        "    for mon in lstmonths:\n",
        "      monS = str(mon) +'_Stripe'\n",
        "      monCM = str(mon) +'_CM'\n",
        "\n",
        "      if (row[monS] != row[monCM]):\n",
        "        if not((pd.isna(row[monS])) and (pd.isna(row[monCM]))) :\n",
        "          if  not( (row[monS] == 0.0) and pd.isna(row[monCM])):\n",
        "            if  not( (row[monCM] == 0.0) and pd.isna(row[monS])):\n",
        "              Sdata = \"%.2f\" % float(row[monS])\n",
        "              CMdata =\"%.2f\" % float(row[monCM])\n",
        "              if Sdata != CMdata:\n",
        "                df1 = {\"Customer Unique ID\":row[\"Customer Unique ID\"],'Customer Name_Stripe':row['Customer Name_Stripe'], 'Customer Name_CM':row['Customer Name_CM'],\n",
        "                      'Customer Country_Stripe':row['Customer Country_Stripe'],'Customer Plan_Stripe' : row['Customer Plan_Stripe'], 'Customer Plan_CM':row['Customer Plan_CM'],\n",
        "                      'Customer Plan Duration_CM':row['Customer Plan Duration_CM'],  monS:row[monS], monCM : row[monCM]}\n",
        "                dftemp = dftemp.append(df1, ignore_index = True)\n",
        "                \n",
        "    p += 1\n",
        "\n",
        "  #dftemp.to_excel(outpath + 'Stripe Vs CM Differences.xlsx', index=False)\n",
        "  #Sort by first month\n",
        "  dfmerged = dfmerged.sort_values('2020-01_CM')\n",
        "  dfmerged = dfmerged.applymap(lambda x: x.encode('unicode_escape').\n",
        "                 decode('utf-8') if isinstance(x, str) else x)\n",
        "\n",
        "  #dfmerged.to_csv(outpath + 'CM Vs Stripe.csv',index = False)\n",
        "  #dfmerged.to_excel(outpath + 'Stripe Vs CM.xlsx',index = False)\n",
        "\n",
        "  writer = pd.ExcelWriter(outpath + 'Stripe Vs CM.xlsx', engine = 'xlsxwriter')\n",
        "  dfmerged.to_excel(writer, sheet_name = 'Stripe Vs CM', ignore_index = True)\n",
        "  dftemp.to_excel(writer, sheet_name = 'Differences', ignore_index = True)\n",
        "  writer.save()\n",
        "  writer.close()\n",
        "\n",
        "  print('done')\n",
        "\n",
        "else:\n",
        "\n",
        "  print(\"No input files found!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e0d46d-c992-4156-d973-40b4755f84b6",
        "id": "smeo1ijK3ITV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/xlsxwriter/workbook.py:339: UserWarning: Calling close() on already closed file.\n",
            "  warn(\"Calling close() on already closed file.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "writer = pd.ExcelWriter(outpath + 'Stripe Vs CM.xlsx', engine = 'xlsxwriter')\n",
        "dfmerged.to_excel(writer, sheet_name = 'Stripe Vs CM', index = False)\n",
        "dftemp.to_excel(writer, sheet_name = 'Differences', index = False)\n",
        "writer.save()\n",
        "writer.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7437e22-1f58-4743-d657-ff59c123ce82",
        "id": "MUbRc13_3ITd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/xlsxwriter/workbook.py:339: UserWarning: Calling close() on already closed file.\n",
            "  warn(\"Calling close() on already closed file.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t501hiKi3ITe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excel Formatting to highlight the differences"
      ],
      "metadata": {
        "id": "_ojURU4r3ITe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
        "writer = pd.ExcelWriter(outpath + 'CM Vs Stripe.xlsx', engine='xlsxwriter', engine_kwargs={'options':{'strings_to_formulas': False}})\n",
        "dfmerged.to_excel(writer, index=False, sheet_name='report')\n",
        "\n",
        "# Get access to the workbook and sheet\n",
        "workbook = writer.book\n",
        "worksheet = writer.sheets['report']\n",
        "\n",
        "# Reduce the zoom a little\n",
        "worksheet.set_zoom(90)\n",
        "#Set column width\n",
        "worksheet.set_column('A:G', 20)\n",
        "\n",
        "# Add a format. Light red background with bolded text\n",
        "format1 = workbook.add_format({'bg_color': '#FFC7CE', 'bold': True})\n",
        "\n",
        "start_row=1\n",
        "start_col=7\n",
        "end_row=len(dfmerged)-1\n",
        "end_col=8\n",
        "\n",
        "worksheet.conditional_format(start_row, start_col, end_row, end_col, \n",
        "                             {'type': 'formula',\n",
        "                              'criteria': '= H1 == I1', \n",
        "                              'format': format1})\n",
        "\n",
        "writer.save()\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "625c5b44-9e5f-4760-c1ac-d4718ae56d51",
        "id": "soKyvo413ITf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/xlsxwriter/workbook.py:339: UserWarning: Calling close() on already closed file.\n",
            "  warn(\"Calling close() on already closed file.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BIo4u4n23ITg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excel Formatting to highlight the differences"
      ],
      "metadata": {
        "id": "27FJcZHP1kfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
        "writer = pd.ExcelWriter(outpath + 'CM Vs Stripe.xlsx', engine='xlsxwriter', engine_kwargs={'options':{'strings_to_formulas': False}})\n",
        "dfmerged.to_excel(writer, index=False, sheet_name='report')\n",
        "\n",
        "# Get access to the workbook and sheet\n",
        "workbook = writer.book\n",
        "worksheet = writer.sheets['report']\n",
        "\n",
        "# Reduce the zoom a little\n",
        "worksheet.set_zoom(90)\n",
        "#Set column width\n",
        "worksheet.set_column('A:G', 20)\n",
        "\n",
        "# Add a format. Light red background with bolded text\n",
        "format1 = workbook.add_format({'bg_color': '#FFC7CE', 'bold': True})\n",
        "\n",
        "start_row=1\n",
        "start_col=7\n",
        "end_row=len(dfmerged)-1\n",
        "end_col=8\n",
        "\n",
        "worksheet.conditional_format(start_row, start_col, end_row, end_col, \n",
        "                             {'type': 'formula',\n",
        "                              'criteria': '= H1 == I1', \n",
        "                              'format': format1})\n",
        "\n",
        "writer.save()\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g4hWphzm_c0",
        "outputId": "625c5b44-9e5f-4760-c1ac-d4718ae56d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/xlsxwriter/workbook.py:339: UserWarning: Calling close() on already closed file.\n",
            "  warn(\"Calling close() on already closed file.\")\n"
          ]
        }
      ]
    }
  ]
}